{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frozen Lake Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lake (on a square grid). Your task is to make it from the start on top-left to the end on the bottom-right in as few steps as possible. There are two complecating factors:\n",
    "\n",
    "1. The ice is slippy so when you make a move (up,down,left, right) there is a chance you don't go where you intended.\n",
    "2. The ice has cracks in it so there is a chance you fall down a crack (and die!)\n",
    "\n",
    "With the probabilities of moving known and the cracks known. This defines an MDP that we can solve with value iteration of policy iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load some packages\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# The main modules that we need\n",
    "import gym\n",
    "from stochastic_control.optimal_control.discrete_control \\\n",
    "import Value_Iteration, Policy_Iteration\n",
    "\n",
    "from tqdm import tqdm\n",
    "from imp import reload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lake(vi,size=8):\n",
    "    '''prints the solution more nicely '''  \n",
    "    \n",
    "    # print the lake\n",
    "    env.render()\n",
    "    print('')\n",
    "    \n",
    "    # print the solution\n",
    "    A_dict = { 0 : 'L', 1: 'D', 2:'R', 3:'U' }\n",
    "    for s in range(vi.nS):\n",
    "        print(A_dict[vi.act(s)], end='')\n",
    "        if (s+1) % size ==0 :\n",
    "            print('')\n",
    "    \n",
    "    # print values/sucess_probabilities\n",
    "    print('')\n",
    "    for s in range(vi.nS):\n",
    "        print(np.round(vi.V[s],2), end=' ')\n",
    "        if (s+1) % size ==0 :\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment\n",
    "env = gym.make('FrozenLake-v0', map_name=None, is_slippery=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFHFFFHF\n",
      "FFFFFFHF\n",
      "FHHHHFFF\n",
      "HHFFFHFF\n",
      "HFFFHFFF\n",
      "FFFFFHFF\n",
      "HFHFFFFF\n",
      "HFFFFFFG\n",
      "\n",
      "DLLRRLLR\n",
      "UUDUULLR\n",
      "LLLLLRDD\n",
      "LLDDLLRD\n",
      "LDDLLDRD\n",
      "DRUDLLRD\n",
      "LLLRDDRD\n",
      "LRDRRRRL\n",
      "\n",
      "0.0 0.0 0.0 0.01 0.01 0.01 0.0 0.06 \n",
      "0.0 0.0 0.0 0.0 0.01 0.02 0.0 0.08 \n",
      "0.0 0.0 0.0 0.0 0.0 0.03 0.1 0.13 \n",
      "0.0 0.0 0.02 0.02 0.01 0.0 0.17 0.2 \n",
      "0.0 0.02 0.03 0.04 0.0 0.08 0.26 0.31 \n",
      "0.01 0.03 0.05 0.1 0.11 0.0 0.38 0.46 \n",
      "0.0 0.03 0.0 0.17 0.26 0.38 0.54 0.71 \n",
      "0.0 0.06 0.11 0.2 0.31 0.46 0.71 0.0 \n"
     ]
    }
   ],
   "source": [
    "# value iteration solution\n",
    "vi = Value_Iteration(env.nS,env.nA,env.P,disc=0.9)\n",
    "V = vi.train(10000)\n",
    "print_lake(vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy is optimal\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFHHHF\n",
      "FFFFFFFF\n",
      "HFFFHFFF\n",
      "FFHHFFFF\n",
      "FFFFFFFF\n",
      "HHFFFHHF\n",
      "FFFFFFFG\n",
      "\n",
      "RRRRUUUR\n",
      "DRRLLLLR\n",
      "URRUDDDD\n",
      "LRULLRDD\n",
      "DLLLDRRD\n",
      "UUDDDUUR\n",
      "LLRRLLLR\n",
      "DDRRDDDL\n",
      "\n",
      "0.0 0.0 0.01 0.01 0.01 0.02 0.03 0.05 \n",
      "0.0 0.0 0.01 0.01 0.0 0.0 0.0 0.06 \n",
      "0.0 0.01 0.01 0.01 0.02 0.06 0.08 0.1 \n",
      "0.0 0.01 0.01 0.0 0.0 0.09 0.12 0.15 \n",
      "0.01 0.01 0.0 0.0 0.06 0.11 0.16 0.23 \n",
      "0.02 0.02 0.05 0.07 0.09 0.12 0.2 0.37 \n",
      "0.0 0.0 0.07 0.1 0.12 0.0 0.0 0.63 \n",
      "0.04 0.05 0.09 0.13 0.21 0.36 0.63 0.0 \n"
     ]
    }
   ],
   "source": [
    "# policy iteration solution\n",
    "poi = Policy_Iteration(env.nS,env.nA,env.P,disc=.9)\n",
    "V = poi.train(time=15)\n",
    "print_lake(poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
