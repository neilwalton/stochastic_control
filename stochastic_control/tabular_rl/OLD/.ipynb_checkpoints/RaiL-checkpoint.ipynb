{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Q-learner discrete\n",
    "    -- Debug for all dicrete states in GYM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "sequentially adds points works for upto five lines.\n",
    "Example usage:\n",
    "my_plot = rolling_plot(2)\n",
    "for i in range(10):\n",
    "    my_plot.plot(i)\n",
    "    my_plot.plot(i**2)\n",
    "my_plot.clear\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "class rolling_plot():\n",
    "    def __init__(self,n_indicies=1):\n",
    "        self.n_indicies = n_indicies\n",
    "        self.x_values = []\n",
    "        self.colors = ['k','b','r','m','c'] \n",
    "        for _ in range(self.n_indicies):\n",
    "            self.x_values.append([])        \n",
    "    \n",
    "    def plot(self,x,index=0):\n",
    "        self.x_values[index].append(x)\n",
    "        display.clear_output(wait=True)\n",
    "        for idx in range(self.n_indicies):\n",
    "            plt.plot(list(range(len(self.x_values[idx]))),self.x_values[idx], color=self.colors[idx])\n",
    "        display.display(plt.gcf())\n",
    "        plt.clf()\n",
    "        \n",
    "    def clear(self):\n",
    "        self.x_values = []\n",
    "        for _ in range(self.n_indicies):\n",
    "            self.x_values.append([])\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "if not number or string, tries to make a string otherwise hashes\n",
    "'''\n",
    "def set_type_function(x):\n",
    "    if not isinstance(x, (int, float, str, np.number)):\n",
    "        try:\n",
    "            x = str(x)\n",
    "        except:\n",
    "            x = hash(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''You need a bandit class for each time that you try an arm'''\n",
    "class Bandit:\n",
    "    pass\n",
    "\n",
    "    def GLIE(self):   \n",
    "        pass\n",
    "    \n",
    "    def Thompson(self):\n",
    "        pass\n",
    "        \n",
    "    def UCB(self):\n",
    "        pass\n",
    "        \n",
    "    def KL_UCB(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. need add state function\n",
    "2. encorperate bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Policy: given a state returns and action\n",
    "    1. Can turn a Q_function to a policy\n",
    "    2. \n",
    "'''\n",
    "\n",
    "class Policy:\n",
    "    def __init__(self,Q_function=None):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.policy = dict() # stores current state, actions\n",
    "        if Q_function is not None:\n",
    "            self.policy = self.Q_load(Q_function)\n",
    "            \n",
    "    '''CHECK THIS'''\n",
    "    def action(self,state,actions=None,bandits=False):\n",
    "        state = self.set_type(state)\n",
    "        # NEED TO ADD STATE IF NOT IN STATES\n",
    "        try:\n",
    "            return self.policy[state]\n",
    "        except KeyError :\n",
    "            if actions is not None :\n",
    "                return np.random.choice(actions)\n",
    "            else :\n",
    "                return np.random.choice(self.actions)\n",
    "    '''\n",
    "    Takes a Q-function and creates a policy\n",
    "    '''\n",
    "    def Q_load(self,Q_function):       \n",
    "        P = Q_function.Q_factor.loc[Q.Q_factor['argmax']==1. , []]\n",
    "        P = P.reset_index()\n",
    "        P = P.set_index('state') \n",
    "        P = P.to_dict()['action']\n",
    "        self.policy = P\n",
    "        self.actions = Q_function.actions\n",
    "        self.states = Q_function.states\n",
    "        return self.policy  \n",
    "    \n",
    "    '''\n",
    "    adds a new state, for each actions (actions can be specified)\n",
    "    '''\n",
    "    def add_state(self,state,actions=None):\n",
    "        pass\n",
    "        \n",
    "    '''\n",
    "    if not number or string, tries to make a string otherwise hashes\n",
    "    '''\n",
    "    def set_type(self,x):\n",
    "        return set_type_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Q_function:\n",
    "    def __init__(self,Q=None):\n",
    "        self.states_dict = dict()\n",
    "        self.actions_dict = dict()\n",
    "        self.states=[]\n",
    "        self.actions=[]\n",
    "        self.Q_factor = self.empty() # Q-factors (and more)\n",
    "        \n",
    "    '''\n",
    "    Q-learning update\n",
    "    '''\n",
    "    def Q_learn(self,state,action,reward,learning_rate=None,discount_rate=1.,actions=None):    \n",
    "        # housekeeping: reformat and add states and actions to dataframe\n",
    "        self.add_state(state,action)\n",
    "        state = self.set_type(state)\n",
    "        action = self.set_type(action)\n",
    "            \n",
    "        '''Do the Q-learning step'''\n",
    "        # the current Q-factor\n",
    "        Q = self.Q_factor.loc[state,action]['Q-factor'] \n",
    "        # the direction of change\n",
    "        dQ = reward \\\n",
    "            + discount_rate * np.max(self.Q_factor.loc[state]['Q-factor']) \\\n",
    "            - self.Q_factor.loc[state,action]['Q-factor']       \n",
    "        # This is the main Q-learning step\n",
    "        Q = Q + learning_rate * ( dQ )       \n",
    "        # update the Q-factor vaue\n",
    "        self.Q_factor.loc[state,action]['Q-factor'] = Q\n",
    "        \n",
    "        # update the row for that state\n",
    "        self.row_update(state,action)            \n",
    "        self.sort()\n",
    "        \n",
    "    '''\n",
    "    SARSA update\n",
    "    '''\n",
    "    def SARSA(self,state,action,reward,state_next,action_next,learning_rate=0.01,discount_rate=1.):    \n",
    "        # housekeeping: reformat and add states and actions to dataframe           \n",
    "        self.add_state(state,action)\n",
    "        state = self.set_type(state)\n",
    "        action = self.set_type(action)\n",
    "        state_next = self.set_type(state_next)\n",
    "        action_next = self.set_type(action_next)\n",
    "        self.add_state(state_next,action_next)\n",
    "        \n",
    "        '''Do the Sarsa step'''\n",
    "        # The current Q-factors\n",
    "        Q = self.Q_factor.loc[state,action]['Q-factor'] \n",
    "        Q_next = self.Q_factor.loc[state_next,action_next]['Q-factor'] \n",
    "        # The sarsa direction of change\n",
    "        dQ = reward \\\n",
    "            + discount_rate * Q_next \\\n",
    "            - Q\n",
    "        # This is the main sarsa step\n",
    "        Q = Q + learning_rate * ( dQ )\n",
    "        # update the Q-factor vaue\n",
    "        self.Q_factor.loc[state,action]['Q-factor'] = Q\n",
    "        \n",
    "        # update the row for that state\n",
    "        self.row_update(state,action)          \n",
    "        self.sort()\n",
    "\n",
    "    '''\n",
    "    SARSA Lambda update\n",
    "    '''\n",
    "    def SARSA_lambda(self,state,action,reward,state_next,action_next,learning_rate=0.01,Lambda=0.5,discount_rate=1.):\n",
    "        # housekeeping: reformat and add states and actions to dataframe           \n",
    "        self.add_state(state,action)\n",
    "        state = self.set_type(state)\n",
    "        action = self.set_type(action)\n",
    "        state_next = self.set_type(state_next)\n",
    "        action_next = self.set_type(action_next)\n",
    "        self.add_state(state_next,action_next)\n",
    "\n",
    "        # add to current state and action\n",
    "        self.Q_factor.loc[state,action]['eligibility trace'] += 1\n",
    "        \n",
    "        Q = self.Q_factor.loc[state,action]['Q-factor'] \n",
    "        Q_next = self.Q_factor.loc[state_next,action_next]['Q-factor'] \n",
    "        # The sarsa direction of change\n",
    "        dQ = reward \\\n",
    "            + discount_rate * Q_next \\\n",
    "            - Q\n",
    "        \n",
    "        # update all states and actions\n",
    "        Qf.Q_factor['Q-factor'] = Qf.Q_factor['Q-factor'] \\\n",
    "                                + learning_rate * ( dQ ) * Qf.Q_factor['eligibility trace'] \n",
    "        Qf.Q_factor['eligibility trace'] = Lambda * discount_rate * Qf.Q_factor['eligibility trace']\n",
    "        \n",
    "        # update the row for that state\n",
    "        self.row_update(state,action)          \n",
    "        self.sort()        \n",
    "            \n",
    "    '''\n",
    "    adds a new state, for each actions (actions can be specified)\n",
    "    '''\n",
    "    def add_state(self,state,actions=None):           \n",
    "        #  This allows for list and non list input\n",
    "        if not isinstance(actions, list) :\n",
    "            actions = [actions]  \n",
    "            \n",
    "        # Reformat all states and actions\n",
    "        self.states_dict[self.set_type(state)]=state \n",
    "        state = self.set_type(state)\n",
    "        for i, a in enumerate(actions):\n",
    "            self.actions_dict[self.set_type(a)]=a\n",
    "            actions[i] = self.set_type(a)\n",
    "         \n",
    "        # find out if the state is new and which actions are new and update\n",
    "        # Add state to state set if new (actions stays as is)\n",
    "        states = self.states.copy()\n",
    "        if state not in states :\n",
    "            self.states.append(state)            \n",
    "        # Define actions and add to action set if new        \n",
    "        new_actions = []       \n",
    "        if actions is None:\n",
    "            actions=self.actions\n",
    "        else: \n",
    "            # if not list then make it a list             \n",
    "            for a in actions:\n",
    "                # if action not seen before add it to the action set\n",
    "                if a not in self.actions :\n",
    "                    self.actions.append(a)                                                                     \n",
    "                # if state seen before but action not seen before add to new actions\n",
    "                if state in states :\n",
    "                    # get all \n",
    "                    state_actions = self.Q_factor.loc[state].index\n",
    "                    if a not in state_actions:\n",
    "                        new_actions.append(a)\n",
    "                    # we only add new rows for new actions\n",
    "                    actions = new_actions               \n",
    "        \n",
    "        '''\n",
    "        if state not seen so far or there exist new_actions,\n",
    "        create a new entry for each of actions\n",
    "        '''\n",
    "        if state not in states or new_actions :\n",
    "            #Define the indicies of a multi-index dataframe\n",
    "            array_states = [ state for a in actions ] \n",
    "            array_actions = [ a for a in actions ]  \n",
    "            arrays = [ array_states, array_actions ]\n",
    "            #Make the date frame giving names to indicies and columns\n",
    "            Q = pd.DataFrame( np.zeros((len(array_actions), 5)),\\\n",
    "                             columns = ['Q-factor', 'argmax', 'value', 'occupancy','eligibility trace'],\\\n",
    "                             index = arrays )\n",
    "            Q.index.names = [ 'state', 'action' ]\n",
    "            #Define the set of states and actions\n",
    "            self.Q_factor = self.Q_factor.append(Q) if self.Q_factor is not None \\\n",
    "                                                    else Q\n",
    "        \n",
    "        self.sort()\n",
    "\n",
    "    '''\n",
    "    updates additional row statistics for a state\n",
    "    if action specified then updates occupancy too\n",
    "    '''\n",
    "    def row_update(self,state,action=None):        \n",
    "        # update argmax and value row : get biggest Q factor and update for each action for       \n",
    "        max_arg = self.Q_factor.loc[ state ][ 'Q-factor' ].idxmax()\n",
    "        max_value = self.Q_factor.loc[ state , max_arg ][ 'Q-factor' ]\n",
    "        for a in self.Q_factor.loc[ state ].index:\n",
    "            if a == max_arg :\n",
    "                self.Q_factor.loc[ state , a ]['argmax'] = 1.\n",
    "            else :\n",
    "                self.Q_factor.loc[ state , a ]['argmax'] = 0.\n",
    "                \n",
    "            self.Q_factor.loc[ state , a ]['value'] = max_value\n",
    "        # update the occupancy for action\n",
    "        if action is not None :\n",
    "            self.Q_factor.loc[ state , action ]['occupancy'] += 1              \n",
    "        \n",
    "        \n",
    "    '''\n",
    "    Bellman Error:\n",
    "    the mean squared error of all the Q-functions in Bellman Equation\n",
    "    '''\n",
    "    def bellman_error(self,state_action_reward):            \n",
    "        pass\n",
    "       \n",
    "\n",
    "        \n",
    "    '''\n",
    "    if not number or string, tries to make a string otherwise hashes\n",
    "    '''\n",
    "    def set_type(self,x):\n",
    "        return set_type_function(x)\n",
    "   \n",
    "    '''\n",
    "    Gives an empty dataframe\n",
    "    '''\n",
    "    def empty(self):\n",
    "        Q = pd.DataFrame( columns = ['Q-factor', 'argmax', 'value', 'occupancy','eligibility trace'],\\\n",
    "                            index = [ [], [] ] )\n",
    "        Q.index.names = [ 'state', 'action' ]\n",
    "            \n",
    "        return Q \n",
    "    \n",
    "    def sort(self):\n",
    "        try:\n",
    "            self.Q_factor = self.Q_factor.sort_index()\n",
    "        except TypeError : \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are HERE!!\n",
    "    2. Perhaps just remove the argmax from the Q-matrix? then sort with policy?\n",
    "    2. Think about data types\n",
    "    2. Get learning rate to do something sensible if set None\n",
    "    3. Get Q_factor table import function\n",
    "    4. Parallelization\n",
    "    5. Bellman error\n",
    "    6. import matlib plot if not already imported -- local import for module\n",
    "    7. Make a multi-thread version\n",
    "    8. where should set type be if in both classes ?\n",
    "    9. Get policy to chose random action if non exists\n",
    "    10. Raise key error in action function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
